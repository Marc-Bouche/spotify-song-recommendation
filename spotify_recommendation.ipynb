{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a78177-9e7d-4235-b25d-686fd18a2c3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Welcome to the Spotify Project**!\n",
    "\n",
    "After reading the Gnod Project Introduction, you are now ready to develop the product that Jane, the CTO of Gnod, asked you to create. You will present it on Friday, where it will be live-tested to assess how good your song recommendations are! \n",
    "\n",
    "\n",
    "[**Spotify API Documentation**](https://spotipy.readthedocs.io/en/2.24.0/#api-reference)\n",
    "[**GitHub Repository**](https://github.com/Marc-Bouche/spotify-song-recommendation)\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "### DAY 1:\n",
    "**Objective:**\n",
    "- Install necessary libraries and create a Spotify developer account (if not done).\n",
    "- Create a DataFrame with the top 100 songs and respective artists by scraping the website [Billboard Hot 100](https://www.billboard.com/charts/hot-100/).\n",
    "  - The DataFrame should have 2 columns: `song_title`, `artist`.\n",
    "\n",
    "- Create a Python program that takes a user input, checks if it is present in your scraped DataFrame.\n",
    "  - If it is, it recommends a random song from the DataFrame.\n",
    "  - If itâ€™s not, it prints: `Sorry, your song is not popular`.\n",
    "  - *Important note*: For now, you will not use the DataFrame of audio features you created yesterday.\n",
    "\n",
    "\n",
    "### DAY 2:\n",
    "**Objective:**\n",
    "  - Using the `Spotipy` library, create a DataFrame storing the `audio_features` of at least 1000 songs.\n",
    "  - [**Audio features explanation**](https://developer.spotify.com/documentation/web-api/reference/get-audio-features)\n",
    "  - The more diverse your playlist, the better the end result will be!\n",
    "\n",
    "### DAY 3:\n",
    "**Objective:**\n",
    "- Using one of the Unsupervised Learning Algorithms that we have covered, create a model using the audio features DataFrame you created on Tuesday.\n",
    "\n",
    "### DAY 4:\n",
    "**Objective:**\n",
    "- Finalize the project: Your final program should check if a song is present in your scraped `billboard_hot100` DataFrame.\n",
    "  - If it is, it should recommend a random song from that DataFrame.\n",
    "  - If not, it should recommend a song based on musical similarity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8449000-dd1b-4901-ab55-665895d999d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Libraries Import & Settings** print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b10ebf22-6dfa-4e21-aa6c-fcd47cbf032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Third-party library imports\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "from textblob import TextBlob\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# Spotipy library imports\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy\n",
    "from spotipy.exceptions import SpotifyException\n",
    "\n",
    "\n",
    "import pickle\n",
    "from sklearn import datasets \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06a0f373-b739-46d9-928c-e914812063b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0e161-9b5e-4b10-91a9-03e1637d20a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Billboard Hot 100 hits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a29d13f9-b800-4ab9-b0ed-5a802fa89045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://www.billboard.com/charts/hot-100/\"\n",
    "#response = requests.get(url)\n",
    "\n",
    "#if response.status_code == 200:\n",
    "#    print(\"Page fetched successfully!\")\n",
    "#    html_content = response.content\n",
    "#else:\n",
    "#    print(\"Failed to retrieve the page!\")\n",
    "\n",
    "#soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Scrape song titles\n",
    "#songs = [song.get_text(strip=True) for song in soup.select(\"li.o-chart-results-list__item h3\")]\n",
    "\n",
    "# Scrape artist names\n",
    "#artists = [artist.get_text(strip=True) for artist in soup.select(\"li.o-chart-results-list__item h3 + span\")]\n",
    "\n",
    "# Scrape ranks\n",
    "#ranks = range(1, len(songs) + 1)\n",
    "\n",
    "# Combine data into a DataFrame\n",
    "#billboard_hot_100 = pd.DataFrame({\n",
    "#    \"song_title\": songs,\n",
    "#    \"artist\": artists\n",
    "#})\n",
    "\n",
    "#billboard_hot_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53ee97d8-83f8-4b41-96f6-77c0e3fde691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a subfolder in the current directory\n",
    "#file_path = '/Users/mbouch17/Desktop/IronHack/Labs &  Project/spotify-song-recommendation/csv_files/billboard_hot_100.csv'\n",
    "\n",
    "# Save to CSV\n",
    "#billboard_hot_100.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd743db-a4f4-4562-96e2-aaf664bbb8ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  **iTunes DE Top 100 songs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1413b2c2-4ecf-4edc-a6fe-7d366f66a61e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# URL of the PopVortex Germany Top Songs page\n",
    "#url2 = \"https://www.popvortex.com/music/germany/top-songs.php\"\n",
    "\n",
    "# Fetch the page content\n",
    "#response = requests.get(url2)\n",
    "#response.raise_for_status()  # Ensure the request was successful\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "#soup2 = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Locate song titles and artists based on the updated structure\n",
    "#titles = [title.text.strip() for title in soup2.select(\"cite.title\")]\n",
    "#artists = [artist.text.strip() for artist in soup2.select(\"em.artist\")]\n",
    "\n",
    "# Create a DataFrame\n",
    "#itunes_de_100 = pd.DataFrame({\n",
    "#    \"song_title\": titles,\n",
    "#    \"artist\": artists\n",
    "#})\n",
    "\n",
    "# Save to CSV\n",
    "#itunes_de_100.to_csv(\"/Users/mbouch17/Desktop/IronHack/Labs &  Project/spotify-song-recommendation/csv_files/iTunes_DE_100.csv\", index=False)\n",
    "#itunes_de_100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fa341-a26a-491a-9fe2-caadfa17f132",
   "metadata": {},
   "source": [
    "## **Merge WW & DE dataframe | 'ww_de'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13698976-ac2f-40fd-b30c-1c886d8d4387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add origin columns to each DataFrame\n",
    "#billboard_hot_100[\"origin\"] = \"WW\"\n",
    "#itunes_de_100[\"origin\"] = \"DE\"\n",
    "\n",
    "# Normalize song titles for case-insensitive matching\n",
    "#billboard_hot_100[\"song_title_normalized\"] = billboard_hot_100[\"song_title\"].str.lower()\n",
    "#itunes_de_100[\"song_title_normalized\"] = itunes_de_100[\"song_title\"].str.lower()\n",
    "\n",
    "# Merge the two DataFrames on normalized song titles\n",
    "#merged_df = pd.merge(\n",
    "#    billboard_hot_100,\n",
    "#    itunes_de_100,\n",
    "#    on=\"song_title_normalized\",\n",
    " #   suffixes=('_billboard', '_itunes'),\n",
    " #   how=\"outer\"\n",
    "#)\n",
    "\n",
    "# Determine the origin column\n",
    "#def determine_origin(row):\n",
    "#    if pd.notnull(row[\"origin_billboard\"]) and pd.notnull(row[\"origin_itunes\"]):\n",
    "#        return \"WW_DE\"\n",
    "#    elif pd.notnull(row[\"origin_billboard\"]):\n",
    "#        return \"WW\"\n",
    "#    elif pd.notnull(row[\"origin_itunes\"]):\n",
    "#        return \"DE\"\n",
    "#    return None\n",
    "\n",
    "#merged_df[\"origin\"] = merged_df.apply(determine_origin, axis=1)\n",
    "\n",
    "# Create the final DataFrame with only the required columns\n",
    "#ww_de = pd.DataFrame({\n",
    "#    \"song_title\": merged_df[\"song_title_normalized\"].str.title(),\n",
    "#    \"artist\": merged_df[\"artist_billboard\"].combine_first(merged_df[\"artist_itunes\"]),\n",
    "#    \"origin\": merged_df[\"origin\"]\n",
    "#})\n",
    "\n",
    "#ww_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8812aa53-6b33-4fff-b696-7f8fa280f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a subfolder in the current directory\n",
    "#file_path = '/Users/mbouch17/Desktop/IronHack/Labs &  Project/spotify-song-recommendation/csv_files/ww_de.csv'\n",
    "\n",
    "# Save to CSV\n",
    "#ww_de.to_csv(file_path, index=False)\n",
    "#ww_de.head(60)\n",
    "\n",
    "# URL of the CSV file\n",
    "url = 'https://raw.githubusercontent.com/Marc-Bouche/spotify-song-recommendation/refs/heads/main/csv_files/ww_de.csv'\n",
    "\n",
    "# Importing the CSV into a DataFrame\n",
    "ww_de = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e69fdb-17ea-4ee4-a62e-866e65dd688a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **User Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e96061f-0ee2-451f-92a5-fe6dd8621f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a song title or artist:  25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found a match: 25 by Rod Wave\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you like a random song recommendation from the list? (yes/no):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, no recommendations at the moment.\n"
     ]
    }
   ],
   "source": [
    "## Function to recommend song\n",
    "def recommend_song(user_input):\n",
    "    # Normalize input to lowercase and remove extra spaces\n",
    "    user_input = user_input.strip().lower()\n",
    "\n",
    "    # Use spelling correction to handle minor typos\n",
    "    user_input = str(TextBlob(user_input).correct())\n",
    "\n",
    "    # Use fuzzywuzzy to match the input with song_title or artist\n",
    "    titles = ww_de['song_title'].tolist()\n",
    "    artists = ww_de['artist'].tolist()\n",
    "\n",
    "    # Try to match the input with song titles and artists\n",
    "    matched_title, score_title = process.extractOne(user_input, titles)\n",
    "    matched_artist, score_artist = process.extractOne(user_input, artists)\n",
    "\n",
    "    # Set a threshold for acceptable match scores (e.g., 80%)\n",
    "    if score_title >= 80 or score_artist >= 80:\n",
    "        # Show matched song and artist\n",
    "        matched_song_info = ww_de[(ww_de['song_title'] == matched_title) | (ww_de['artist'] == matched_artist)]\n",
    "        \n",
    "        print(f\"\\nFound a match: {matched_song_info.iloc[0]['song_title']} by {matched_song_info.iloc[0]['artist']}\")\n",
    "        \n",
    "        # Ask for confirmation before recommending a random song\n",
    "        while True:\n",
    "            confirm = input(\"Would you like a random song recommendation from the list? (yes/no): \").strip().lower()\n",
    "\n",
    "            if confirm == 'yes':\n",
    "                # Recommend a random song\n",
    "                random_song = ww_de.sample(n=1).iloc[0]\n",
    "                print(f\"How about this one: {random_song['song_title']} by {random_song['artist']}\")\n",
    "                return True  # Continue to menu\n",
    "            elif confirm == 'no':\n",
    "                print(\"Okay, no recommendations at the moment.\")\n",
    "                return False  # Indicate to stop\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
    "    else:\n",
    "        print(\"Sorry, no popular match found for your song or artist.\")\n",
    "    return True  # Continue processing\n",
    "\n",
    "# Main program\n",
    "def main():\n",
    "    while True:\n",
    "        user_input = input(\"Enter a song title or artist: \").strip()\n",
    "        \n",
    "        if user_input:\n",
    "            continue_recommendation = recommend_song(user_input)\n",
    "            if not continue_recommendation:\n",
    "                break  # Exit the main loop if user says 'no'\n",
    "\n",
    "            while True:\n",
    "                # Ask user for the next action\n",
    "                choice = input(\"\\nWould you like to:\\n(1) Get another recommendation based on the same artist/song\\n(2) Type a new artist/song\\n(3) Exit\\nEnter 1, 2, or 3: \").strip()\n",
    "\n",
    "                if choice == '1':\n",
    "                    # Get another recommendation and return to this menu\n",
    "                    continue_recommendation = recommend_song(user_input)\n",
    "                    if not continue_recommendation:\n",
    "                        return  # Exit the entire program\n",
    "                elif choice == '2':\n",
    "                    # Ask for a new artist/song\n",
    "                    break\n",
    "                elif choice == '3':\n",
    "                    print(\"Thank you for using the song recommendation system!\")\n",
    "                    return  # Exit the entire program\n",
    "                else:\n",
    "                    print(\"Invalid input. Please enter 1, 2, or 3.\")\n",
    "        else:\n",
    "            print(\"Please enter a valid song title or artist.\")\n",
    "\n",
    "# Start the program\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e0b13-c6f5-4ca0-9397-ecda1af1a5d1",
   "metadata": {},
   "source": [
    "## **Spotify**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f329b-42f0-40ae-a8d1-66c9d3229899",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Connect API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4537cdd-9b02-470a-a35b-4f0a89212758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotify_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00b4ba8c-a6db-4316-98a3-096be4751dee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize SpotiPy with user credentials\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sp \u001b[38;5;241m=\u001b[39m spotipy\u001b[38;5;241m.\u001b[39mSpotify(auth_manager\u001b[38;5;241m=\u001b[39mSpotifyClientCredentials(client_id\u001b[38;5;241m=\u001b[39m\u001b[43mclient_id\u001b[49m,client_secret\u001b[38;5;241m=\u001b[39mclient_secret))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client_id' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize SpotiPy with user credentials\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id,client_secret=client_secret))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee09d7d-4470-4359-a02a-ce1d2c42c9c3",
   "metadata": {},
   "source": [
    "### Fetch [**audio features**](https://developer.spotify.com/documentation/web-api/reference/get-audio-features) of 1000+ songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d95b6-4a99-43cb-a50e-b8ae16ebd2b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "####  LIST OF GENRE 1 : ['love', 'dance', 'happy', 'rock', 'pop', 'jazz', 'indie', 'classical', 'hip hop', 'chill', 'blues', 'reggae', 'party', 'electronic', 'latin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676ace7-4d8c-4b3b-b918-a85da53f3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch track IDs based on search queries\n",
    "#def get_track_ids(query, limit=50, offset=0):\n",
    "#    results = sp.search(q=query, type='track', limit=limit, offset=offset)\n",
    "#    return [track['id'] for track in results['tracks']['items']]\n",
    "\n",
    "# Function to fetch audio features for a list of track IDs\n",
    "#def get_audio_features(track_ids):\n",
    "#    features = sp.audio_features(track_ids)\n",
    "#    return [f for f in features if f]  # Filter out None results\n",
    "\n",
    "# Generate a diverse list of queries\n",
    "#queries = ['love', 'dance', 'happy', 'rock', 'pop', 'jazz', 'indie', 'classical', \n",
    "#           'hip hop', 'chill', 'blues', 'reggae', 'party', 'electronic', 'latin']\n",
    "\n",
    "# Fetch and process data\n",
    "#all_features = []\n",
    "#seen_track_ids = set()  # To ensure unique tracks\n",
    "\n",
    "# Outer loop to iterate over queries\n",
    "#for query in queries:\n",
    "#    for offset in range(0, 1000, 50):  # Iterate with offsets to get more tracks\n",
    "#        track_ids = get_track_ids(query, limit=50, offset=offset)\n",
    "#        unique_track_ids = [t for t in track_ids if t not in seen_track_ids]  # Filter unique IDs\n",
    "#        seen_track_ids.update(unique_track_ids)\n",
    "\n",
    "#        features = get_audio_features(unique_track_ids)  # Fetch audio features\n",
    "#        all_features.extend(features)  # Append to the master list\n",
    "\n",
    "#        if len(all_features) >= 1000:  # Stop once we have 1000+ songs\n",
    "#            break\n",
    "\n",
    "#    if len(all_features) >= 1000:  # Stop outer loop if we hit the target\n",
    "#        break\n",
    "\n",
    "# Create a DataFrame from the features\n",
    "#df_audio_features = pd.DataFrame(all_features)\n",
    "\n",
    "# Fetch track details in bulk\n",
    "#tracks = sp.tracks([track['id'] for track in all_features])  # Fetch track details in bulk\n",
    "\n",
    "# Map artist and song names to the corresponding track IDs\n",
    "#df_audio_features['artist'] = df_audio_features['id'].map(lambda track_id: next((track['artists'][0]['name'] for track in tracks['tracks'] if track['id'] == track_id), 'Unknown'))\n",
    "#df_audio_features['song'] = df_audio_features['id'].map(lambda track_id: next((track['name'] for track in tracks['tracks'] if track['id'] == track_id), 'Unknown'))\n",
    "\n",
    "# Reorder the columns to place 'id', 'artist', and 'song' at the start\n",
    "#df_audio_features = df_audio_features[['id', 'artist', 'song'] + [col for col in df_audio_features.columns if col not in ['id', 'artist', 'song']]]\n",
    "\n",
    "# Save to CSV\n",
    "#df_audio_features.to_csv(\"/Users/mbouch17/Desktop/IronHack/Labs &  Project/spotify-song-recommendation/csv_files/df_audio_features.csv\", index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "#df_audio_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea26fc-ee98-494c-b2d1-2157e0e690fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_audio_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a72f4-42e6-4e97-9013-536fd0e5d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the song using the song id in track_id!\n",
    "\n",
    "track_id = '7aQjPecQdIuNd1sz3KCDhD'\n",
    "#track_id= 'spotify:track:3hgl7EQwTutSm6PESsB7gZ'\n",
    "IFrame(src=\"https://open.spotify.com/embed/track/\"+track_id,\n",
    "       width=\"320\",\n",
    "       height=\"80\",\n",
    "       frameborder=\"0\",\n",
    "       allowtransparency=\"true\",\n",
    "       allow=\"encrypted-media\",\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692ad8b-1b4f-4007-9951-3e3d1e910bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_audio_features.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65205011-9625-41c5-91a9-6f424e6925dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_audio_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ec381-3442-4b8d-849c-d1f0751f1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to CSV\n",
    "# df_audio_features.to_csv(\"/Users/mbouch17/Desktop/IronHack/Labs &  Project/spotify-song-recommendation/csv_files/df_audio_features_with_artist_song.csv\", index=False)\n",
    "# df_audio_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c7e2b-3d08-492d-89a7-340bd671c960",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "####  LIST OF GENRE 2: ['country', 'metal', 'alternative', 'folk', 'punk', 'r&b', 'soul', 'techno', 'house', 'disco', 'ambient', 'industrial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ae54c-1766-440e-a9ed-1b6bd399f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_track_metadata_with_backoff(track_ids, retries=5):\n",
    "#    \"\"\"\n",
    "#    Fetch artist and song metadata for a list of track IDs with retry logic.\n",
    "#    \"\"\"\n",
    "#    track_metadata = []\n",
    "#    for i in range(retries):\n",
    "#        try:\n",
    "#            for track_id in track_ids:\n",
    "#                track = sp.track(track_id)  # Fetch track details\n",
    "#                track_metadata.append({\n",
    "#                    'id': track_id,\n",
    "#                    'artist': ', '.join([artist['name'] for artist in track['artists']]),  # Handles multiple artists\n",
    "#                    'song': track['name']\n",
    "#                })\n",
    "#            return track_metadata\n",
    "#        except Exception as e:\n",
    "#            if i < retries - 1:\n",
    "#                time.sleep(2 ** i)  # Exponential backoff\n",
    "#            else:\n",
    "#                raise e\n",
    "\n",
    "# Assuming `df_audio_features2` is created in your original code\n",
    "# Extract unique track IDs from the DataFrame\n",
    "#unique_track_ids = df_audio_features2['id'].unique()\n",
    "\n",
    "# Fetch metadata for the unique track IDs\n",
    "#metadata = fetch_track_metadata_with_backoff(unique_track_ids)\n",
    "\n",
    "# Convert metadata to a DataFrame\n",
    "#df_metadata = pd.DataFrame(metadata)\n",
    "\n",
    "# Merge metadata with the original audio features DataFrame\n",
    "#df_audio_features2 = df_metadata.merge(df_audio_features2, on='id')\n",
    "\n",
    "# Reorder columns to place artist, song, and id at the beginning\n",
    "#columns_order = ['artist', 'song', 'id'] + [col for col in df_audio_features2.columns if col not in ['artist', 'song', 'id']]\n",
    "#df_audio_features2 = df_audio_features2[columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd9fe8-872f-41b1-90cb-0ac1f24754b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_track_ids_with_retry(query, limit=50, offset=0, retries=5):\n",
    "#    for i in range(retries):\n",
    "#        try:\n",
    "#            return sp.search(q=query, type='track', limit=limit, offset=offset)['tracks']['items']\n",
    "#        except Exception as e:\n",
    "#            if i < retries - 1:\n",
    "#                time.sleep(2 ** i)  # Exponential backoff\n",
    "#            else:\n",
    "#                raise e\n",
    "\n",
    "#def fetch_audio_features_with_backoff(track_ids, retries=5):\n",
    "#    for i in range(retries):\n",
    "#        try:\n",
    "#            return sp.audio_features(track_ids)\n",
    "#        except Exception as e:\n",
    "#            if i < retries - 1:\n",
    "#                time.sleep(2 ** i)  # Exponential backoff\n",
    "#            else:\n",
    "#                raise e\n",
    "\n",
    "# Main processing loop\n",
    "#all_features = []\n",
    "#seen_track_ids = set()\n",
    "\n",
    "#queries = ['country', 'metal', 'alternative', 'folk', 'punk', 'r&b', 'soul', 'techno', 'house', 'disco', 'ambient', 'industrial']\n",
    "\n",
    "#for query in queries:\n",
    "#    for offset in range(0, 1000, 50):\n",
    "#        tracks = get_track_ids_with_retry(query=query, limit=50, offset=offset)\n",
    "#        track_ids = [t['id'] for t in tracks if t['id'] not in seen_track_ids]\n",
    "#        seen_track_ids.update(track_ids)\n",
    "\n",
    "#        features = fetch_audio_features_with_backoff(track_ids)\n",
    "#        all_features.extend(f for f in features if f)  # Filter None results\n",
    "\n",
    "#        if len(all_features) >= 1000:\n",
    "#            break\n",
    "#    if len(all_features) >= 1000:\n",
    "#        break\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "# df_audio_features2 = pd.DataFrame(all_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab242b7-be66-43c5-9028-9b769c3c5252",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Fetching Popular playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74bbb31-aad5-4a09-92ea-2712fec54d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch audio features of songs in chunks of 100\n",
    "#def fetch_audio_features(song_ids):\n",
    "#    audio_features = []\n",
    "    \n",
    "    # Split the list of song IDs into chunks of 100\n",
    "#    for i in range(0, len(song_ids), 100):\n",
    "#        chunk = song_ids[i:i + 100]\n",
    "#        try:\n",
    "#            # Fetch audio features for the current chunk\n",
    "#            features = sp.audio_features(chunk)\n",
    "#            audio_features.extend(features)\n",
    "#        except Exception as e:\n",
    "#            print(f\"Error fetching audio features for chunk: {chunk}\\n{e}\")\n",
    "    \n",
    "#    return audio_features\n",
    "\n",
    "# Assuming you want at least 2000 songs\n",
    "# Fetch more songs if needed (example shown for adding more songs if your data source allows it)\n",
    "#song_ids = playlist_songs_df['track_id'].tolist()  # Extract track IDs\n",
    "\n",
    "# If there are fewer than 2000 songs, extend the list (Example for adding more, adapt to your data source)\n",
    "#num_songs = len(song_ids)\n",
    "#if num_songs < 2000:\n",
    "#    print(f\"Warning: Only {num_songs} songs are available. Adding more songs to meet the minimum requirement.\")\n",
    "    # You can append more song IDs here from another source or playlist\n",
    "    # Example: song_ids.extend(extra_song_ids)  # extra_song_ids needs to be defined elsewhere\n",
    "    \n",
    "# Fetch the audio features for the songs\n",
    "#audio_features = fetch_audio_features(song_ids)\n",
    "\n",
    "# Convert the audio features into a DataFrame\n",
    "#audio_features_df = pd.DataFrame(audio_features)\n",
    "\n",
    "# Merge audio features with the playlist songs DataFrame\n",
    "#df_playlist = pd.concat([playlist_songs_df, audio_features_df], axis=1)\n",
    "\n",
    "# Assuming df_combined contains your existing songs dataset, merge the new songs\n",
    "#df_combined = pd.concat([df_combined, df_playlist], ignore_index=True)\n",
    "\n",
    "# Display the updated DataFrame with audio features\n",
    "#df_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7da5f-2635-4de4-9101-6db3441289a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c925bde-58d7-4221-91f7-f6f7c7990adb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d70c2-c819-41ee-818c-a9094b1b3d8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Merge & Clean Audio features dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a7617-1887-4ef1-a906-9302d218923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the CSV file\n",
    "url = 'https://raw.githubusercontent.com/Marc-Bouche/spotify-song-recommendation/refs/heads/main/csv_files/df_audio_features_with_artist_song.csv'\n",
    "\n",
    "# Importing the CSV into a DataFrame\n",
    "df_audio_features = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to check the data\n",
    "df_audio_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c79da5-5e07-445e-9879-8e3f5cfa97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the CSV file\n",
    "url2 = 'https://raw.githubusercontent.com/Marc-Bouche/spotify-song-recommendation/refs/heads/main/csv_files/df_audio_features2.csv'\n",
    "\n",
    "# Importing the CSV into a DataFrame\n",
    "df_audio_features2 = pd.read_csv(url2)\n",
    "\n",
    "# Display the first few rows to check the data\n",
    "df_audio_features2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54567420-e9f7-4496-9e81-a9d1dc9d7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'id' with an outer join to keep all data\n",
    "#df_combined = df_audio_features.merge(df_audio_features2, on='id', how='outer')\n",
    "\n",
    "# Combine the columns (e.g., 'danceability', 'energy', etc.) using combine_first\n",
    "#columns_to_combine = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', \n",
    "#                      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', \n",
    "#                      'type', 'uri', 'track_href', 'analysis_url', 'duration_ms', 'time_signature']\n",
    "\n",
    "#for col in columns_to_combine:\n",
    "    # Combine the '_x' and '_y' columns\n",
    "#    df_combined[col] = df_combined[f'{col}_x'].combine_first(df_combined[f'{col}_y'])\n",
    "\n",
    "    # Drop the '_x' and '_y' columns after combining\n",
    "#    df_combined.drop(columns=[f'{col}_x', f'{col}_y'], inplace=True)\n",
    "\n",
    "# Drop 'artist_x', 'artist_y', 'song_x', 'song_y' after combining them as well\n",
    "#df_combined['artist'] = df_combined['artist_x'].combine_first(df_combined['artist_y'])\n",
    "#df_combined['song'] = df_combined['song_x'].combine_first(df_combined['song_y'])\n",
    "#df_combined.drop(columns=['artist_x', 'artist_y', 'song_x', 'song_y'], inplace=True)\n",
    "\n",
    "# Drop the 'artist' and 'song' columns\n",
    "#df_combined.drop(columns=['artist', 'song'], inplace=True)\n",
    "\n",
    "#df_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81b1a5-7277-4f5e-9869-1c35e0751052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching track data\n",
    "#def get_track_info_with_retry(track_id, retries=5):\n",
    "#    for i in range(retries):\n",
    "#        try:\n",
    "#            track = sp.track(track_id, market='US')  # Specify the market to avoid region-specific issues\n",
    "#            artist_name = track['artists'][0]['name']  # Get the name of the first artist\n",
    "#            song_name = track['name']  # Get the song name\n",
    "#            return artist_name, song_name\n",
    "#        except spotipy.exceptions.SpotifyException as e:\n",
    "#            if i < retries - 1:\n",
    "#                print(f\"Error fetching track {track_id}: {e}. Retrying...\")\n",
    "#                time.sleep(2 ** i)  # Exponential backoff\n",
    "#            else:\n",
    "#                print(f\"Error fetching track {track_id}: {e}. No more retries.\")\n",
    "#                return None, None  # Return None if unable to fetch after retries\n",
    "\n",
    "# Function to fetch artist and song for each track ID\n",
    "#def fetch_artist_and_song(df):\n",
    "#    # Apply the retry function for each ID to get artist and song\n",
    "#    df['artist'], df['song'] = zip(*df['id'].apply(lambda x: get_track_info_with_retry(x)))\n",
    "#    return df\n",
    "\n",
    "# Assuming df_combined is the dataframe with your track IDs\n",
    "#df_combined = fetch_artist_and_song(df_combined)\n",
    "\n",
    "# Verify the result\n",
    "#print(df_combined[['id', 'artist', 'song']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5e777-439b-4dd0-a5da-7440554f9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90376b7-c346-443a-bd28-b8a7abbbe69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f290a-bb30-4dc7-a3fb-13008abbe426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666e25c-f50f-4ef9-9477-e496ffa4408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "# df_combined.to_csv(\"/Users/mbouch17/Desktop/IronHack/Labs &  Project/spotify-song-recommendation/csv_files/df_combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31c0291-7d09-4990-b397-53dadfb40a13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  **Unsupervised Learning Algorithms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22f83f-94e1-46b8-a7fa-05116b767248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# URL of the CSV file\n",
    "url3 = 'https://raw.githubusercontent.com/Marc-Bouche/spotify-song-recommendation/refs/heads/main/csv_files/df_combined.csv'\n",
    "\n",
    "# Importing the CSV into a DataFrame\n",
    "df_combined = pd.read_csv(url3)\n",
    "\n",
    "# Renaming 'song' to 'song_title' to align with ww_de dataframe\n",
    "df_combined.rename(columns={'song': 'song_title'}, inplace=True)\n",
    "\n",
    "# Display the first few rows to check the data\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68f261-7154-4bbe-a406-854761739a8b",
   "metadata": {},
   "source": [
    "### Clustering K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc302b-6995-4843-a3ea-1a98044ccfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Select Features\n",
    "features = df_combined[['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo']]\n",
    "\n",
    "# Step 2: Normalize Features\n",
    "scaler = StandardScaler()\n",
    "try:\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    print(\"Feature scaling completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during feature scaling: {e}\")\n",
    "\n",
    "# Check for NaN or inf in scaled features\n",
    "if np.isnan(features_scaled).sum() > 0 or np.isinf(features_scaled).sum() > 0:\n",
    "    raise ValueError(\"Features contain NaN or inf values after scaling.\")\n",
    "\n",
    "# Step 3: Apply K-Means Clustering\n",
    "try:\n",
    "    kmeans = KMeans(n_clusters=8, random_state=42)  # Adjust 'n_clusters' as needed\n",
    "    df_combined['cluster'] = kmeans.fit_predict(features_scaled)\n",
    "    print(\"K-Means clustering completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during K-Means clustering: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd475dd5-c359-47a1-b118-500daa9aeabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method\n",
    "sse = []\n",
    "sil_scores = []\n",
    "\n",
    "# Try different values for K (clusters) from 1 to 15\n",
    "for k in range(1, 16):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(features_scaled)\n",
    "    sse.append(kmeans.inertia_)  # Sum of squared distances to closest cluster center\n",
    "    if k > 1:  # Silhouette score is undefined for k=1, so start from k=2\n",
    "        sil_score = silhouette_score(features_scaled, kmeans.labels_)\n",
    "        sil_scores.append(sil_score)\n",
    "\n",
    "# Plot Elbow Method\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SSE (Elbow Method)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, 16), sse, marker='o', color='blue')\n",
    "plt.title('Elbow Method (SSE vs. K)')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Sum of Squared Errors (SSE)')\n",
    "\n",
    "# Plot Silhouette Scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(2, 16), sil_scores, marker='o', color='green')\n",
    "plt.title('Silhouette Score vs. K')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Pick the Best K\n",
    "# You can use the Elbow Method and/or Silhouette Score to pick the optimal K.\n",
    "# Based on the plots, you can decide the best K.\n",
    "\n",
    "# For example, if the Elbow Method suggests K=5 and Silhouette Score suggests K=5 as well, we choose K=5.\n",
    "best_k = 5  # Choose based on the elbow plot and silhouette score plot\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "df_combined['cluster'] = kmeans.fit_predict(features_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb56f3-5f20-4934-8789-5e3a5f6d36db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794a683-36e1-4088-9d37-aeaa71bcbca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Agglomerative Clustering\n",
    "try:\n",
    "    # Create Agglomerative Clustering model\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=8, linkage='ward')  # Adjust 'n_clusters' as needed\n",
    "    df_combined['cluster'] = agglomerative.fit_predict(features_scaled)\n",
    "    print(\"Agglomerative clustering completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during Agglomerative clustering: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08f20db-2a3c-4cf0-a5fb-1eb16a2d829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# Step 1: Extract Cluster Labels\n",
    "cluster_labels = df_combined['cluster']\n",
    "\n",
    "# Step 2: Check for Valid Clusters\n",
    "if len(set(cluster_labels)) <= 1:  # Ensure we have at least 2 clusters for meaningful evaluation\n",
    "    print(\"Agglomerative Clustering did not form enough clusters for evaluation.\")\n",
    "else:\n",
    "    # Step 3: Silhouette Score\n",
    "    silhouette_avg = silhouette_score(features_scaled, cluster_labels)\n",
    "    print(f\"Silhouette Score: {silhouette_avg:.2f}\")\n",
    "    \n",
    "    # Step 4: Davies-Bouldin Index (lower is better)\n",
    "    davies_bouldin = davies_bouldin_score(features_scaled, cluster_labels)\n",
    "    print(f\"Davies-Bouldin Index: {davies_bouldin:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c06b3-0cdc-40eb-bcc5-161028f0dc2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6eab0-bab4-499d-a05b-c6d2d1263d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN Clustering\n",
    "\n",
    "try:\n",
    "    # Parameters: eps (maximum distance between points) and min_samples (minimum points to form a cluster)\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5)  # Adjust these parameters as needed\n",
    "    df_combined['cluster'] = dbscan.fit_predict(features_scaled)\n",
    "    print(\"DBSCAN clustering completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during DBSCAN clustering: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1bad5c-0357-4de1-93e1-0150458a2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract Cluster Labels\n",
    "cluster_labels = df_combined['cluster']\n",
    "\n",
    "# Step 2: Check for Valid Clusters\n",
    "# DBSCAN might assign -1 to noise points, so we need to ensure we have valid clusters\n",
    "if len(set(cluster_labels)) <= 1:  # DBSCAN needs at least 2 clusters for meaningful evaluation\n",
    "    print(\"DBSCAN did not form enough clusters for evaluation.\")\n",
    "else:\n",
    "    # Step 3: Silhouette Score (ignores noise points, requires more than 1 cluster)\n",
    "    silhouette_avg = silhouette_score(features_scaled[cluster_labels != -1], cluster_labels[cluster_labels != -1])\n",
    "    print(f\"Silhouette Score: {silhouette_avg:.2f}\")\n",
    "    \n",
    "    # Step 4: Davies-Bouldin Index (lower is better, evaluates all points including noise)\n",
    "    davies_bouldin = davies_bouldin_score(features_scaled, cluster_labels)\n",
    "    print(f\"Davies-Bouldin Index: {davies_bouldin:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a6751-a21f-4b60-a574-6b58d92ea658",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Final recommendation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad015b-b186-4b6b-9e35-03991e43825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full workflow\n",
    "def full_workflow(user_input):\n",
    "    search_results = sp.search(q=user_input, type='track,artist', limit=1)\n",
    "    \n",
    "    if not search_results['tracks']['items'] and not search_results['artists']['items']:\n",
    "        print(f\"No results found for '{user_input}'.\")\n",
    "        return\n",
    "    \n",
    "    if search_results['tracks']['items']:\n",
    "        # If input matches a song, fetch audio features\n",
    "        track = search_results['tracks']['items'][0]\n",
    "        print(f\"Found song: {track['name']} by {track['artists'][0]['name']}\")\n",
    "        \n",
    "        # Check if the song is present in the ww_de DataFrame\n",
    "        if track['name'] in ww_de['song_title'].values:\n",
    "            print(f\"The song '{track['name']}' is found in your ww_de DataFrame.\")\n",
    "            # Recommend one random song from ww_de\n",
    "            random_recommendation = ww_de.sample(n=1)\n",
    "            print(\"Recommended Song from ww_de:\")\n",
    "            print(random_recommendation[['song_title', 'artist']])\n",
    "            # Play the recommended song\n",
    "            for song in random_recommendation['song_title']:\n",
    "                play_song(song)\n",
    "        else:\n",
    "            user_audio_features = get_audio_features(track['id'])\n",
    "            \n",
    "            if user_audio_features:\n",
    "                user_features_scaled = prepare_user_features(user_audio_features, scaler, feature_columns)\n",
    "                user_cluster = kmeans.predict(user_features_scaled)[0]\n",
    "                print(f\"Song '{track['name']}' belongs to cluster {user_cluster}.\")\n",
    "                # Recommend one song based on musical similarity from the user's cluster\n",
    "                recommendations = recommend_from_cluster(df_combined, user_cluster)\n",
    "                recommended_song = recommendations[['song_title', 'artist']].iloc[0]  # Get the first recommendation\n",
    "                print(\"Recommended Song based on musical similarity:\")\n",
    "                print(recommended_song)\n",
    "                # Play the recommended song\n",
    "                play_song(recommended_song['song_title'])\n",
    "            else:\n",
    "                print(f\"Unable to retrieve audio features for '{track['name']}'.\")\n",
    "    \n",
    "    elif search_results['artists']['items']:\n",
    "        # If input matches an artist, fetch songs from that artist\n",
    "        artist = search_results['artists']['items'][0]\n",
    "        print(f\"Found artist: {artist['name']}\")\n",
    "        artist_tracks = sp.artist_top_tracks(artist['id'])['tracks']\n",
    "\n",
    "        if artist_tracks:\n",
    "            print(f\"Top song by {artist['name']}:\")\n",
    "            # Recommend only the top song\n",
    "            top_song = artist_tracks[0]\n",
    "            print(f\"- {top_song['name']} (Listen: https://open.spotify.com/track/{top_song['id']})\")\n",
    "        else:\n",
    "            print(f\"No top tracks found for artist '{artist['name']}'.\")\n",
    "\n",
    "# Dynamic User Input\n",
    "user_input = input(\"Enter a song or artist name: \")\n",
    "full_workflow(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3658ec-f417-401b-892f-71ce8d5f25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"Spotify Song Recommendation\")\n",
    "st.write(\"Welcome to the app!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e9b6f-5073-48db-adb0-f53950994aa0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Streamlit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47feaaac-ac03-449a-adb0-782ab5d40d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Open Visual Code Studio\n",
    "# 2. Right click on 'app.py'\n",
    "# 3. Open in Integrated Terminal\n",
    "# 4. Run 'streamlit run app.py'\n",
    "# 5. A new browser tab opens : http://localhost:8502/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
